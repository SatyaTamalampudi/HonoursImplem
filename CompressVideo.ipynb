{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OS module in Python provides a way of using operating system dependent functionality.\n",
    "Python method listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "os.chdir() method in Python used to change the current working directory to specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tetal\\AI\\DividedDataSet\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder which contains all the images \n",
    "# from which video is to be generated \n",
    "path = \"C:\\\\Users\\\\tetal\\\\AI\\\\DividedDataSet\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "mean_height = 0\n",
    "mean_width = 0\n",
    "\n",
    "num_of_images = len(os.listdir('.')) \n",
    "print(num_of_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'C:\\\\Users\\\\tetal\\\\AI\\\\DividedDataSet\\\\Training\\\\Train024' # make sure to use your folder \n",
    "#video_name = 'mygeneratedvideo2.mp4\n",
    "\n",
    "images = [img for img in os.listdir(path) \n",
    "if img.endswith(\".tif\") or\n",
    "    img.endswith(\".jpeg\") or\n",
    "    img.endswith(\"png\")] \n",
    "#print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\tetal\\\\AI\\\\DividedDataSet\\\\Testing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-adac78f41277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmean_width\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmean_height\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\tetal\\\\AI\\\\DividedDataSet\\\\Testing'"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('.'): \n",
    "    im = Image.open(os.path.join(path, file)) \n",
    "    width, height = im.size \n",
    "    mean_width += width \n",
    "    mean_height += height \n",
    "    # im.show() # uncomment this for displaying the image \n",
    "\n",
    "# Finding the mean height and width of all images. \n",
    "# This is required because the video frame needs \n",
    "# to be set with same width and height. Otherwise \n",
    "# images not equal to that width height will not get \n",
    "# embedded into the video \n",
    "mean_width = int(mean_width / num_of_images) \n",
    "mean_height = int(mean_height / num_of_images) \n",
    "\n",
    "# print(mean_height) \n",
    "# print(mean_width) \n",
    "\n",
    "# Resizing of the images to give \n",
    "# them same width and height \n",
    "for file in os.listdir('.'): \n",
    "    if file.endswith(\".tif\") or file.endswith(\".jpeg\") or file.endswith(\"png\"): \n",
    "        # opening image using PIL Image \n",
    "        im = Image.open(os.path.join(path, file)) \n",
    "\n",
    "        # im.size includes the height and width of image \n",
    "        width, height = im.size \n",
    "        print(width, height) \n",
    "\n",
    "        # resizing \n",
    "        imResize = im.resize((238, 158), Image.ANTIALIAS) \n",
    "        imResize.save( file, \"JPEG\",quality = 95) # setting quality \n",
    "        # printing each resized image name \n",
    "        print(im.filename.split('\\\\')[-1], \" is resized\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Generating function \n",
    "def generate_video(images,outvid=None, fps=10, size=None,\n",
    "               is_color=True, format=\"XVID\"): \n",
    "\t#image_folder = 'C:\\\\Users\\\\tetal\\\\AI\\\\Test001' # make sure to use your folder \n",
    "\tvideo_name = 'mygeneratedvideo1.mp4'\n",
    "\t#os.chdir(\"C:\\\\Users\\\\tetal\\\\AI\\\\Test001\") \n",
    "\t\n",
    "\t#images = [img for img in os.listdir(image_folder) \n",
    "\t\t\t#if img.endswith(\".tif\") or\n",
    "\t\t\t\t#img.endswith(\".jpeg\") or\n",
    "\t\t\t\t#img.endswith(\"png\")] \n",
    "\t\n",
    "\t# Array images should only consider \n",
    "\t# the image files ignoring others if any \n",
    "\t#print(images) \n",
    "\n",
    "\tframe = cv2.imread(os.path.join(image_folder, images[0])) \n",
    "\n",
    "\t# setting the frame width, height width \n",
    "\t# the width, height of first image \n",
    "\theight, width, layers = frame.shape \n",
    "\tfourcc = VideoWriter_fourcc(*format)\n",
    "\tvideo = VideoWriter(video_name, fourcc, float(fps), (238, 158), is_color)\n",
    "\n",
    "\t# Appending the images to the video one by one \n",
    "\tfor image in images: \n",
    "\t\tvideo.write(cv2.imread(os.path.join(image_folder, image))) \n",
    "\t\n",
    "\t# Deallocating memories taken for window creation \n",
    "\tcv2.destroyAllWindows() \n",
    "    \n",
    "\tvideo.release() # releasing the video generated \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the generate_video function \n",
    "generate_video(images) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating x,y feature vectors(mag, direction)\n",
    "    Storing all the values from videos to one big array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Big arraycontains magnitude of all the videos in training set\n",
    "mag_Bigarray_train = []\n",
    "mag_Bigarray_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satya\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('mygeneratedvideo1.mp4')\n",
    "print(\"satya\")\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 25,\n",
    "                       qualityLevel = 0.2,\n",
    "                       minDistance = 4,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "count=0\n",
    "index = 0;\n",
    "ret,frame = cap.read()\n",
    "while(ret):\n",
    "   \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    #print(err)\n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    #print(good_new)\n",
    "    good_old = p0[st==1]\n",
    "    #print(good_old)\n",
    "    \n",
    "    \n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        \n",
    "        \n",
    "        a,b = new.ravel()\n",
    "        #print(a,b)\n",
    "        c,d = old.ravel()\n",
    "        #print(c,d)\n",
    "\n",
    "        #print(c-a,d-b)\n",
    "        if((a>c) & (b>d)):\n",
    "            mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    cv2.imshow('frame',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    #print(p0)\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7483196,)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"mygeneratedvideo68.mp4\")\n",
    "ret, frame1 = cap.read() #returns a bool (True/False). If frame is read correctly, it will be True. So you can check end of the video by checking this return value.\n",
    "#print(frame1.shape)\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1) # Return a array of zeros of same type and shape as given array\n",
    "hsv[...,1] = 255\n",
    "count=0\n",
    "index = 0;\n",
    "ret, frame2 = cap.read()\n",
    "mag_fullarray = []\n",
    "#print(mag_fullarray)\n",
    "while(ret):\n",
    "   \n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY) #For BGR \\rightarrow Gray conversion we use the flags cv2.COLOR_BGR2GRAY\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    #prvs = next;\n",
    "    pixel_array = np.array(flow)\n",
    "    #print(pixel_array[0].shape)\n",
    "    #print (\"flow\",flow)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    #print(\"magnitude\",mag)\n",
    "    #print(mag.shape)\n",
    "    flattened_image = mag.flatten() # flatten the whole array as one input instead of 439 inputs\n",
    "    mag_fullarray.append(flattened_image)\n",
    "    \n",
    "    #flattened_image = mag.flatten() # flatten the whole array as one input instead of 439 inputs\n",
    "    \n",
    "    #mag_array = np.array(mag)\n",
    "    #print(mag_array.shape)\n",
    "    #print(\"mag\",mag.shape)\n",
    "    #plt.hist(mag_array,bins=3)\n",
    "    #plt.show()\n",
    "    #print(len((mag_array)))\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    #print(hsv)\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    #if count==10:\n",
    "        #count=0\n",
    "        \n",
    "       # print (\"flow\",flow)\n",
    "        \n",
    "    cv2.imshow('frame2',rgb)\n",
    "    count=count+1\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):    \n",
    "        prvs = next\n",
    "    ret, frame2 = cap.read()\n",
    "    index = index+1\n",
    "    #print(index)\n",
    "\n",
    "\n",
    "mag_array = np.array(mag_fullarray)\n",
    "#print(\"magfullarray\",mag_fullarray[0])\n",
    "flatten_video = mag_array.flatten() # flatten the whole array as one input instead of 439 inputs\n",
    "print(flatten_video.shape)\n",
    "flatten_video.reshape((199,37604))\n",
    "#print(flatten_video.shape[1])\n",
    "#mag_Bigarray_train = np.array(flatten_video)\n",
    "#mag_Bigarray_train += flatten_video\n",
    "mag_Bigarray_test.append(flatten_video)\n",
    "#print(\"mag_Bigarray_train\",mag_Bigarray_train[45])\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(7483196,)\n"
     ]
    }
   ],
   "source": [
    "print(len(mag_Bigarray_test))\n",
    "print((mag_Bigarray_test[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0.02112589 0.01366441 0.01793827 ... 0.01037669 0.00979749 0.00808257]\n"
     ]
    }
   ],
   "source": [
    "print(type(mag_Bigarray_test[0]))\n",
    "print((mag_fullarray[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "from numpy import load\n",
    "#save('training_data1.npy',mag_Bigarray_train) ##Saving numpy array\n",
    "#save('testing_data2.npy',mag_Bigarray_test) ##Saving numpy array\n",
    "\n",
    "train_data = load('training_data1.npy',allow_pickle=True)\n",
    "test_data = load('testing_data1.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 7483196)\n",
      "(20, 7483196)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print((train_data.shape))\n",
    "labels_X = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "#labels = [1,0,1]\n",
    "#print(labels[47])\n",
    "labels_Y = [1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0]\n",
    "print(test_data.shape)\n",
    "X_train = train_data\n",
    "Y_train = labels_X\n",
    "X_test  = test_data\n",
    "Y_test = labels_Y\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf', gamma=\"auto\")\n",
    "#svclassifier = SVC(kernel='sigmoid')\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 8]\n",
      " [4 6]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25        10\n",
      "           1       0.43      0.60      0.50        10\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.38      0.40      0.38        20\n",
      "weighted avg       0.38      0.40      0.38        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(Y_test, predictions)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cebdffe4c2bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#cv2.imshow(\"input\", frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Converts each frame to grayscale - we previously only converted the first frame to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Calculates dense optical flow by Farneback method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html#calcopticalflowfarneback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# The video feed is read in as a VideoCapture object\n",
    "cap = cv2.VideoCapture(\"mygeneratedvideo2.mp4\")\n",
    "# ret = a boolean return value from getting the frame, first_frame = the first frame in the entire video sequence\n",
    "ret, first_frame = cap.read()\n",
    "# Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "# Creates an image filled with zero intensities with the same dimensions as the frame\n",
    "mask = np.zeros_like(first_frame)\n",
    "# Sets image saturation to maximum\n",
    "mask[..., 1] = 255\n",
    "# ret = a boolean return value from getting the frame, frame = the current frame being projected in the video\n",
    "ret, frame = cap.read()\n",
    "while(cap.isOpened()):\n",
    "    # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video\n",
    "    #ret, frame = cap.read()\n",
    "    # Opens a new window and displays the input frame\n",
    "    #cv2.imshow(\"input\", frame)\n",
    "    # Converts each frame to grayscale - we previously only converted the first frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculates dense optical flow by Farneback method\n",
    "    # https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html#calcopticalflowfarneback\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Computes the magnitude and angle of the 2D vectors\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Sets image hue according to the optical flow direction\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    # Sets image value according to the optical flow magnitude (normalized)\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # Converts HSV to RGB (BGR) color representation\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    # Opens a new window and displays the output frame\n",
    "    cv2.imshow(\"dense optical flow\", rgb)\n",
    "    # Updates previous frame\n",
    "    prev_gray = gray\n",
    "    # Frames are read by intervals of 1 millisecond. The programs breaks out of the while loop when the user presses the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# The following frees up resources and closes all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "print(len(mag_fullarray[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open(\"001.tif\")\n",
    "#im.show()\n",
    "imarray = np.array(im)\n",
    "print(type(imarray))\n",
    "plt.hist(imarray.ravel(),256,[0,256]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 199\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-22-d28eab09612f>\", line 19, in <module>\n",
      "    plt.savefig('C:/Users/tetal/AI/Test001/New/00%s.png' %(i+1))\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 723, in savefig\n",
      "    fig.canvas.draw_idle()   # need this if 'transparent=True' to reset colors\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 1907, in draw_idle\n",
      "    self.draw(*args, **kwargs)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 388, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 1709, in draw\n",
      "    renderer, self, artists, self.suppressComposite)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 135, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 2647, in draw\n",
      "    mimage._draw_list_compositing_images(renderer, self, artists)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 135, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\patches.py\", line 575, in draw\n",
      "    affine = transform.get_affine()\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 2400, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 2401, in get_affine\n",
      "    self._a.get_affine().get_matrix()))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tetal\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 321, in wrapped\n",
      "    inspect.findsource = save_findsource\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "length = len(mag_fullarray)\n",
    "print(\"length\",length)\n",
    "for i in range (length):\n",
    "    print(i)\n",
    "    mag_array = mag_fullarray[i] \n",
    "    img = images[i+1]\n",
    "    #im1array = cv2.imread(img)\n",
    "    im = Image.open(img)\n",
    "    imarray = np.array(im)\n",
    "    image_array = np.asfarray(imarray).flatten().reshape((158,238))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(image_array)\n",
    "    plt.title(\"Image\")\n",
    "    \n",
    "    plt.subplot(2,2,2)\n",
    "    plt.hist(mag_array,bins=22)\n",
    "    plt.title(\"Histogram\")\n",
    "    \n",
    "    plt.savefig('C:/Users/tetal/AI/Test001/New/00%s.png' %(i+1))\n",
    "    #plt.show()\n",
    "    #plt.imshow(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 0\n",
    "max = 0\n",
    "length = len(mag_fullarray)\n",
    "print(\"length\",length)\n",
    "for i in range (length):\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37604\n",
      "0.6069918\n"
     ]
    }
   ],
   "source": [
    "print(mag_array.size)\n",
    "print(mag_array[0][237])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread('001.tif',0)\n",
    "plt.hist(img.ravel(),3,[0,256]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
